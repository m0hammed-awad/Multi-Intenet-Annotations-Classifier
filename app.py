import os
import glob
import uuid
import logging
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from datetime import datetime

from flask import Flask, render_template, request, jsonify, session, redirect, url_for
from flask_cors import CORS

# Import classifiers and services
from customer_service_classifier import CustomerServiceClassifier
from ai_service import AIService

# ==============================
# Configure logging
# ==============================
logging.basicConfig(level=logging.DEBUG)

app = Flask(__name__)
app.secret_key = os.environ.get("SESSION_SECRET", "dev-secret-key")
CORS(app)

# ==============================
# Initialize AI services
# ==============================
ai_service = AIService()

# ==============================
# Initialize CustomerServiceClassifier
# ==============================
classifier = CustomerServiceClassifier(model_dir="model")
train_path = "Dataset/Bitext_Sample_Customer_Service_Training_Dataset.csv"
test_path = "Dataset/Bitext_Sample_Customer_Service_Testing_Dataset.csv"

# ==============================
# In-memory storage
# ==============================
conversations = {}
analytics_data = {
    'total_conversations': 0,
    'response_times': [],
    'intent_counts': {
        'ACCOUNT': 0, 'CANCELLATION_FEE': 0, 'CONTACT': 0, 'DELIVERY': 0, 'FEEDBACK': 0,
        'INVOICE': 0, 'NEWSLETTER': 0, 'ORDER': 0, 'PAYMENT': 0, 'REFUND': 0, 'SHIPPING_ADDRESS': 0
    },
    'conversation_timeline': [],
    'active_sessions': set()
}

# ==============================
# Template Filter for Footer
# ==============================
@app.template_filter('datetimeformat')
def datetimeformat(value, format='%Y'):
    if value == 'now':
        return datetime.now().strftime(format)
    return value

# ==============================
# Routes
# ==============================
@app.route('/')
def index():
    return render_template('home.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/visuallongation')
def visualization():
    return render_template('visualization.html')

@app.route('/eda')
def eda_page():
    return render_template('eda.html')

@app.route('/prediction')
def predict_page():
    return render_template('predictions.html')

# ==============================
# EDA Endpoint
# ==============================
@app.route('/api/eda', methods=['GET'])
def run_eda():
    try:
        df = classifier.upload_dataset(train_path)
        X, Y_dict = classifier.preprocess_data(df, target_cols=["intent", "category"])

        eda_plot_dir = os.path.join(app.static_folder, 'eda_plots')
        os.makedirs(eda_plot_dir, exist_ok=True)

        original_show = plt.show
        def save_plot():
            plot_filename = f"plot_{uuid.uuid4()}.png"
            plot_path = os.path.join(eda_plot_dir, plot_filename)
            plt.savefig(plot_path, bbox_inches='tight')
            plt.close()
            return os.path.join('eda_plots', plot_filename)
        plt.show = save_plot

        plot_paths = []
        classifier.eda_nlp_analysis(X, num_words=100, top_n_words=20)
        plot_paths.extend([
            os.path.join('eda_plots', f) for f in os.listdir(eda_plot_dir) 
            if f.startswith('plot_') and f.endswith('.png')
        ])

        classifier.plot_target_distributions(Y_dict)
        plot_paths.extend([
            os.path.join('eda_plots', f) for f in os.listdir(eda_plot_dir) 
            if f.startswith('plot_') and f.endswith('.png') and f not in plot_paths
        ])

        plt.show = original_show
        return jsonify({'plots': plot_paths})

    except Exception as e:
        logging.error(f"Error in EDA endpoint: {str(e)}")
        return jsonify({'error': 'Failed to generate EDA visualizations', 'details': str(e)}), 500

# ==============================
# Prediction Endpoint
# ==============================
@app.route('/api/predict', methods=['GET'])
def predict():
    try:
        # Ensure the classifier is trained
        if not classifier.models:
            classifier.fit(train_path, target_cols=["intent", "category"])

        # Run predictions using the test dataset
        predictions_df = classifier.predict(test_path, model_base_name="MiniLM-WE DNN")

        # Convert predictions to a list of dictionaries for JSON response
        predictions = predictions_df.to_dict(orient='records')

        return jsonify({
            'success': True,
            'predictions': predictions,
            'columns': list(predictions_df.columns)
        })

    except Exception as e:
        logging.error(f"Error in prediction endpoint: {str(e)}")
        return jsonify({'error': 'Failed to generate predictions', 'details': str(e)}), 500

# ==============================
# Metrics Endpoints (DTC, NBC, KNN, DNN-KNN)
# ==============================
@app.route('/api/dtc', methods=['GET'])
def dtc_metrics():
    try:
        results_dir = os.path.join(app.static_folder, 'results', 'dtc')
        targets = ['intent', 'category']
        response = {}
        for target in targets:
            target_dir = os.path.join(results_dir, target)
            png_files = glob.glob(os.path.join(target_dir, '*.png')) if os.path.exists(target_dir) else []
            relative_paths = [os.path.join('results', 'dtc', target, os.path.basename(f)).replace(os.sep, '/') 
                             for f in png_files]
            confusion_matrices = [p for p in relative_paths if 'confusion_matrix' in p.lower()]
            roc_curves = [p for p in relative_paths if 'roc_curve' in p.lower()]
            other_files = [p for p in relative_paths if p not in confusion_matrices and p not in roc_curves]
            response[target] = {
                'confusion_matrices': confusion_matrices,
                'roc_curves': roc_curves,
                'other_plots': other_files
            }
        return jsonify(response)
    except Exception as e:
        logging.error(f"Error in DTC metrics endpoint: {str(e)}")
        return jsonify({'error': 'Failed to retrieve DTC metrics', 'details': str(e)}), 500

@app.route('/api/nbc', methods=['GET'])
def nbc_metrics():
    try:
        results_dir = os.path.join(app.static_folder, 'results', 'nbc')
        targets = ['intent', 'category']
        response = {}
        for target in targets:
            target_dir = os.path.join(results_dir, target)
            png_files = glob.glob(os.path.join(target_dir, '*.png')) if os.path.exists(target_dir) else []
            relative_paths = [os.path.join('results', 'nbc', target, os.path.basename(f)).replace(os.sep, '/') 
                             for f in png_files]
            confusion_matrices = [p for p in relative_paths if 'confusion_matrix' in p.lower()]
            roc_curves = [p for p in relative_paths if 'roc_curve' in p.lower()]
            other_files = [p for p in relative_paths if p not in confusion_matrices and p not in roc_curves]
            response[target] = {
                'confusion_matrices': confusion_matrices,
                'roc_curves': roc_curves,
                'other_plots': other_files
            }
        return jsonify(response)
    except Exception as e:
        logging.error(f"Error in NBC metrics endpoint: {str(e)}")
        return jsonify({'error': 'Failed to retrieve NBC metrics', 'details': str(e)}), 500

@app.route('/api/knn', methods=['GET'])
def knn_metrics():
    try:
        results_dir = os.path.join(app.static_folder, 'results', 'knn')
        targets = ['intent', 'category']
        response = {}
        for target in targets:
            target_dir = os.path.join(results_dir, target)
            png_files = glob.glob(os.path.join(target_dir, '*.png')) if os.path.exists(target_dir) else []
            relative_paths = [os.path.join('results', 'knn', target, os.path.basename(f)).replace(os.sep, '/') 
                             for f in png_files]
            confusion_matrices = [p for p in relative_paths if 'confusion_matrix' in p.lower()]
            roc_curves = [p for p in relative_paths if 'roc_curve' in p.lower()]
            other_files = [p for p in relative_paths if p not in confusion_matrices and p not in roc_curves]
            response[target] = {
                'confusion_matrices': confusion_matrices,
                'roc_curves': roc_curves,
                'other_plots': other_files
            }
        return jsonify(response)
    except Exception as e:
        logging.error(f"Error in KNN metrics endpoint: {str(e)}")
        return jsonify({'error': 'Failed to retrieve KNN metrics', 'details': str(e)}), 500

@app.route('/api/dnn_knn', methods=['GET'])
def dnn_knn_metrics():
    try:
        results_dir = os.path.join(app.static_folder, 'results', 'MiniLM-WE DNN KNN')
        targets = ['intent', 'category']
        response = {}
        for target in targets:
            target_dir = os.path.join(results_dir, target)
            png_files = glob.glob(os.path.join(target_dir, '*.png')) if os.path.exists(target_dir) else []
            relative_paths = [os.path.join('results', 'MiniLM-WE DNN KNN', target, os.path.basename(f)).replace(os.sep, '/') 
                             for f in png_files]
            confusion_matrices = [p for p in relative_paths if 'confusion_matrix' in p.lower()]
            roc_curves = [p for p in relative_paths if 'roc_curve' in p.lower()]
            other_files = [p for p in relative_paths if p not in confusion_matrices and p not in roc_curves]
            response[target] = {
                'confusion_matrices': confusion_matrices,
                'roc_curves': roc_curves,
                'other_plots': other_files
            }
        return jsonify(response)
    except Exception as e:
        logging.error(f"Error in DNN-KNN metrics endpoint: {str(e)}")
        return jsonify({'error': 'Failed to retrieve DNN-KNN metrics', 'details': str(e)}), 500

# ==============================
# Classifiers page + redirects
# ==============================
@app.route('/classifiers')
def classifiers_page():
    classifier_name = request.args.get('classifier', 'dtc')
    if classifier_name not in ['dtc', 'nbc', 'knn', 'dnn_knn']:
        classifier_name = 'dtc'
    return render_template('classifiers.html', classifier=classifier_name)

@app.route('/dtc')
def dtc_redirect():
    return redirect(url_for('classifiers_page', classifier='dtc'))

@app.route('/nbc')
def nbc_redirect():
    return redirect(url_for('classifiers_page', classifier='nbc'))

@app.route('/knn')
def knn_redirect():
    return redirect(url_for('classifiers_page', classifier='knn'))

@app.route('/dnn_knn')
def dnn_knn_redirect():
    return redirect(url_for('classifiers_page', classifier='dnn_knn'))

# ==============================
# Chat Endpoints
# ==============================
@app.route('/chat')
def chat_page():
    if 'session_id' not in session:
        session['session_id'] = str(uuid.uuid4())
        conversations[session['session_id']] = []
        analytics_data['active_sessions'].add(session['session_id'])
    return render_template('chat.html')
@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        start_time = datetime.now()
        data = request.get_json()

        user_message = data.get('message', '').strip()
        if not user_message:
            return jsonify({'error': 'Message cannot be empty'}), 400

        session_id = session.get('session_id')
        if not session_id:
            return jsonify({'error': 'Session not found'}), 400

        if session_id not in conversations:
            conversations[session_id] = []
            analytics_data['active_sessions'].add(session_id)

        # Save user message
        user_msg = {
            'role': 'user',
            'content': user_message,
            'timestamp': datetime.now().isoformat()
        }
        conversations[session_id].append(user_msg)

        # Initialize variables to avoid UnboundLocalError
        ai_response = "Error: Service unavailable"
        intent_obj = {"intent1": "contact_customer_service", "intent2": "CONTACT", "confidence1": 0.5, "confidence2": 0.5}
        reasoning_details = None

        # ✅ Single API call: returns reply + raw intent data + reasoning
        try:
            ai_response, intent_obj, reasoning_details = ai_service.generate_response(
                user_message,
                conversations[session_id]
            )
        except Exception as e:
            logging.error(f"AIService failure: {str(e)}")
            # Fallback values already set

        # Construct intent display objects for frontend
        try:
            detected_intents = [
                {
                    "intent": str(intent_obj.get("intent1", "contact_customer_service")),
                    "confidence": float(intent_obj.get("confidence1", 0.5)),
                    "reasoning": str(reasoning_details) if reasoning_details else None
                },
                {
                    "intent": str(intent_obj.get("intent2", "CONTACT")),
                    "confidence": float(intent_obj.get("confidence2", 0.5)),
                    "reasoning": str(reasoning_details) if reasoning_details else None
                }
            ]
            
            intent1_display = f"{detected_intents[0]['intent']} ({int(detected_intents[0]['confidence']*100)}%)"
            intent2_display = f"{detected_intents[1]['intent']} ({int(detected_intents[1]['confidence']*100)}%)"
        except Exception as e:
            logging.error(f"Intent formatting error: {str(e)}")
            detected_intents = []
            intent1_display = "unknown (0%)"
            intent2_display = "unknown (0%)"

        # Response time tracking
        response_time = (datetime.now() - start_time).total_seconds() * 1000
        analytics_data['total_conversations'] += 1
        analytics_data['response_times'].append(response_time)

        if len(analytics_data['response_times']) > 100:
            analytics_data['response_times'] = analytics_data['response_times'][-100:]

        # ✅ Count primary intent (intent2)
        primary_intent = intent2_display.split(" ")[0]  # PAYMENT
        analytics_data['intent_counts'][primary_intent] = analytics_data['intent_counts'].get(primary_intent, 0) + 1

        analytics_data['conversation_timeline'].append({
            'timestamp': datetime.now().isoformat(),
            'response_time': response_time
        })

        if len(analytics_data['conversation_timeline']) > 1440:
            analytics_data['conversation_timeline'] = analytics_data['conversation_timeline'][-1440:]

        # Save AI message
        ai_msg = {
            'role': 'assistant',
            'content': ai_response,
            'timestamp': datetime.now().isoformat(),
            'intents': detected_intents,
            'reasoning_details': reasoning_details
        }
        conversations[session_id].append(ai_msg)

        # Final JSON response
        return jsonify({
            'response': ai_response,
            'intent1': intent1_display,
            'intent2': intent2_display,
            'intents': detected_intents,
            'reasoning_details': reasoning_details,
            'timestamp': ai_msg['timestamp']
        })

    except Exception as e:
        import traceback
        logging.error(f"Error in chat endpoint: {str(e)}")
        logging.error(traceback.format_exc())
        return jsonify({
            'error': 'Error processing message',
            'details': str(e) if app.debug else None
        }), 500
        
@app.route('/api/conversation', methods=['GET'])
def get_conversation():
    try:
        session_id = session.get('session_id')
        if not session_id or session_id not in conversations:
            return jsonify({'messages': []})
        return jsonify({'messages': conversations[session_id]})
    except Exception as e:
        logging.error(f"Error getting conversation: {str(e)}")
        return jsonify({'error': 'Failed to retrieve conversation'}), 500

@app.route('/api/clear', methods=['POST'])
def clear_conversation():
    try:
        session_id = session.get('session_id')
        if session_id and session_id in conversations:
            conversations[session_id] = []
        return jsonify({'success': True})
    except Exception as e:
        logging.error(f"Error clearing conversation: {str(e)}")
        return jsonify({'error': 'Failed to clear conversation'}), 500

# ==============================
# Stats & Analytics Endpoints
# ==============================
@app.route('/api/stats')
def get_stats():
    """Get basic system statistics"""
    return jsonify({
        'total_chats': analytics_data['total_conversations'],
        'avg_response_time': int(sum(analytics_data['response_times']) / len(analytics_data['response_times'])) if analytics_data['response_times'] else 0,
        'active_users': len(analytics_data['active_sessions']),
        'system_uptime': 99.9
    })

@app.route('/api/dashboard-data')
def get_dashboard_data():
    """Get dashboard analytics data"""
    import random
    from datetime import datetime, timedelta
    
    # Generate timeline data for last 24 hours
    now = datetime.now()
    timeline_labels = []
    timeline_data = []
    
    for i in range(24):
        hour = now - timedelta(hours=i)
        timeline_labels.insert(0, hour.strftime('%H:00'))
        # Use real data when available, otherwise generate realistic patterns
        base_conversations = len([c for c in analytics_data['conversation_timeline'] 
                                if datetime.fromisoformat(c['timestamp']).hour == hour.hour])
        timeline_data.insert(0, base_conversations + random.randint(0, 5))
    
    return jsonify({
        'active_conversations': len(analytics_data['active_sessions']),
        'avg_response_time': int(sum(analytics_data['response_times']) / len(analytics_data['response_times'])) if analytics_data['response_times'] else random.randint(150, 300),
        'resolved_issues': analytics_data['total_conversations'],
        'satisfaction_score': random.randint(85, 98),
        'conversation_timeline': {
            'labels': timeline_labels,
            'data': timeline_data
        },
        'intent_distribution': [
            analytics_data['intent_counts'].get('TECHNICAL', 0), # Added default to avoid key errors if labels change
            analytics_data['intent_counts'].get('PAYMENT', 0),
            analytics_data['intent_counts'].get('ACCOUNT', 0),
            analytics_data['intent_counts'].get('ORDER', 0),
            analytics_data['intent_counts'].get('CONTACT', 0)
        ],
        'recent_conversations': [
            {
                'time': (datetime.now() - timedelta(minutes=i*5)).strftime('%H:%M'),
                'user_id': list(analytics_data['active_sessions'])[i % len(analytics_data['active_sessions'])] if analytics_data['active_sessions'] else f"user_{i}",
                'intent': list(analytics_data['intent_counts'].keys())[i % 5],
                'status': 'resolved' if i % 3 == 0 else 'in_progress',
                'duration': f"{random.randint(2, 15)}m"
            }
            for i in range(min(10, len(analytics_data['active_sessions']) or 5))
        ]
    })

@app.route('/api/analytics-data')
def get_analytics_data():
    """Get detailed analytics data"""
    import random
    from datetime import datetime, timedelta
    
    time_range = request.args.get('range', '24h')
    
    # Generate response time trend data
    now = datetime.now()
    trend_labels = []
    avg_times = []
    max_times = []
    
    periods = 24 if time_range == '24h' else (7 if time_range == '7d' else 30)
    unit = 'hours' if time_range == '24h' else 'days'
    
    for i in range(periods):
        if unit == 'hours':
            time_point = now - timedelta(hours=i)
            trend_labels.insert(0, time_point.strftime('%H:00'))
        else:
            time_point = now - timedelta(days=i)
            trend_labels.insert(0, time_point.strftime('%m/%d'))
        
        # Use real response times when available
        period_times = [rt for rt in analytics_data['response_times'][-periods:]]
        if period_times:
            avg_times.insert(0, int(sum(period_times) / len(period_times)))
            max_times.insert(0, int(max(period_times)))
        else:
            avg_times.insert(0, random.randint(200, 400))
            max_times.insert(0, random.randint(500, 800))
    
    return jsonify({
        'current_response_time': analytics_data['response_times'][-1] if analytics_data['response_times'] else random.randint(150, 300),
        'throughput_per_min': random.randint(5, 20),
        'active_connections': len(analytics_data['active_sessions']),
        'error_rate': random.randint(0, 3),
        'memory_usage': random.randint(45, 75),
        'cpu_usage': random.randint(20, 60),
        'response_time_trend': {
            'labels': trend_labels,
            'avg_times': avg_times,
            'max_times': max_times
        },
        'status_distribution': [70, 20, 8, 2],  # resolved, in_progress, pending, escalated
        'confidence_distribution': [65, 25, 10],  # high, medium, low
        'accuracy_by_intent': [92, 88, 95, 90, 85],  # technical, billing, account, product, general
        'detailed_analytics': [
            {
                'timestamp': (datetime.now() - timedelta(minutes=i*2)).strftime('%H:%M:%S'),
                'session_id': list(analytics_data['active_sessions'])[i % len(analytics_data['active_sessions'])] if analytics_data['active_sessions'] else f"session_{i}",
                'intent': list(analytics_data['intent_counts'].keys())[i % 5],
                'confidence': random.uniform(0.6, 0.95),
                'response_time': random.randint(150, 400),
                'satisfaction': random.randint(3, 5) if i % 3 == 0 else None,
                'status': 'resolved' if i % 2 == 0 else 'in_progress'
            }
            for i in range(50)
        ]
    })


# ==============================
# Error handlers
# ==============================
@app.errorhandler(404)
def not_found(error):
    return render_template('home.html'), 404

@app.errorhandler(500)
def internal_error(error):
    logging.error(f"Internal server error: {str(error)}")
    return jsonify({'error': 'Internal server error'}), 500

# ==============================
# Run App
# ==============================
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)